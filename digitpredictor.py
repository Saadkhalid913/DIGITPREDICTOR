# -*- coding: utf-8 -*-
"""DIGITPREDICTOR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/157CboRP_Sq48Mvvze33cqmf8dLDWc5qA
"""

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import pandas as pd
from keras.preprocessing import image 
from keras.preprocessing.image import ImageDataGenerator

np.set_printoptions(suppress=True)

"""Processing images """

TRAIN_GENERATOR = ImageDataGenerator(rescale=1./10,
                              shear_range=0.5,
                              zoom_range=0.5,
                              horizontal_flip=True)

TRAINSET = TRAIN_GENERATOR.flow_from_directory(directory="archive/train", 
                                               target_size=(32,32),
                                               batch_size=32,
                                               class_mode = "categorical",
                                               color_mode = "grayscale")

TEST_GENERATOR = ImageDataGenerator(rescale=1./10)

TESTSET = TEST_GENERATOR.flow_from_directory(directory="archive/eval", 
                                               target_size=(32,32), 
                                                batch_size=32,
                                               class_mode = "categorical",
                                             color_mode = "grayscale")

cnn = tf.keras.models.Sequential()
cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, activation="relu", input_shape=[32,32,1]))
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))

cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, activation="relu"))
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))

cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, activation="relu"))
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))


cnn.add(tf.keras.layers.Flatten())

cnn.add(tf.keras.layers.Dense(units=512, activation="relu"))
cnn.add(tf.keras.layers.Dense(units=128, activation="relu"))

cnn.add(tf.keras.layers.Dense(units=10, activation="sigmoid"))

cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

cnn.fit(x=TRAINSET, validation_data=TESTSET, epochs=25)

img = image.load_img("/content/numberimage2.PNG", target_size=(32,32), color_mode="grayscale")
img = image.img_to_array(img)
img = np.array([img])
res = cnn.predict(img)[0]
max = 0
ind = 0

for i, k in enumerate(res):
  if k > max:
    max = k
    ind = i

indices = {TESTSET.class_indices[key]: key for key in TESTSET.class_indices }
print(indices[ind], "%s" % (max*100) + "%")



